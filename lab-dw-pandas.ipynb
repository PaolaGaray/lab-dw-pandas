{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1973e9e-8be6-4039-b70e-d73ee0d94c99",
   "metadata": {},
   "source": [
    "In this lab, we will be working with the customer data from an insurance company, which can be found in the CSV file located at the following link: https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "The data includes information such as customer ID, state, gender, education, income, and other variables that can be used to perform various analyses.\n",
    "\n",
    "Throughout the lab, we will be using the pandas library in Python to manipulate and analyze the data. Pandas is a powerful library that provides various data manipulation and analysis tools, including the ability to load and manipulate data from a variety of sources, including CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045146f-f4f7-44d9-8cd9-130d6400c73a",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "- Customer - Customer ID\n",
    "\n",
    "- ST - State where customers live\n",
    "\n",
    "- Gender - Gender of the customer\n",
    "\n",
    "- Education - Background education of customers \n",
    "\n",
    "- Customer Lifetime Value - Customer lifetime value(CLV) is the total revenue the client will derive from their entire relationship with a customer. In other words, is the predicted or calculated value of a customer over their entire duration as a policyholder with the insurance company. It is an estimation of the net profit that the insurance company expects to generate from a customer throughout their relationship with the company. Customer Lifetime Value takes into account factors such as the duration of the customer's policy, premium payments, claim history, renewal likelihood, and potential additional services or products the customer may purchase. It helps insurers assess the long-term profitability and value associated with retaining a particular customer.\n",
    "\n",
    "- Income - Customers income\n",
    "\n",
    "- Monthly Premium Auto - Amount of money the customer pays on a monthly basis as a premium for their auto insurance coverage. It represents the recurring cost that the insured person must pay to maintain their insurance policy and receive coverage for potential damages, accidents, or other covered events related to their vehicle.\n",
    "\n",
    "- Number of Open Complaints - Number of complaints the customer opened\n",
    "\n",
    "- Policy Type - There are three type of policies in car insurance (Corporate Auto, Personal Auto, and Special Auto)\n",
    "\n",
    "- Vehicle Class - Type of vehicle classes that customers have Two-Door Car, Four-Door Car SUV, Luxury SUV, Sports Car, and Luxury Car\n",
    "\n",
    "- Total Claim Amount - the sum of all claims made by the customer. It represents the total monetary value of all approved claims for incidents such as accidents, theft, vandalism, or other covered events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72419b-20fc-4905-817a-8c83abc59de6",
   "metadata": {},
   "source": [
    "External Resources: https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ece17-e919-4e23-96c0-c7c59778436a",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the data\n",
    "\n",
    "In this challenge, you will use pandas to explore a given dataset. Your task is to gain a deep understanding of the data by analyzing its characteristics, dimensions, and statistical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4e8cd8-a6f6-486c-a5c4-1745b0c035f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer          ST GENDER             Education Customer Lifetime Value  \\\n",
      "0  RB50392  Washington    NaN                Master                     NaN   \n",
      "1  QZ44356     Arizona      F              Bachelor              697953.59%   \n",
      "2  AI49188      Nevada      F              Bachelor             1288743.17%   \n",
      "3  WW63253  California      M              Bachelor              764586.18%   \n",
      "4  GA49547  Washington      M  High School or Below              536307.65%   \n",
      "\n",
      "    Income  Monthly Premium Auto Number of Open Complaints     Policy Type  \\\n",
      "0      0.0                1000.0                    1/0/00   Personal Auto   \n",
      "1      0.0                  94.0                    1/0/00   Personal Auto   \n",
      "2  48767.0                 108.0                    1/0/00   Personal Auto   \n",
      "3      0.0                 106.0                    1/0/00  Corporate Auto   \n",
      "4  36357.0                  68.0                    1/0/00   Personal Auto   \n",
      "\n",
      "   Vehicle Class  Total Claim Amount  \n",
      "0  Four-Door Car            2.704934  \n",
      "1  Four-Door Car         1131.464935  \n",
      "2   Two-Door Car          566.472247  \n",
      "3            SUV          529.881344  \n",
      "4  Four-Door Car           17.269323  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5bcc4-36f4-44fe-af71-7a044c579e99",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "- Identify the dimensions of the dataset by determining the number of rows and columns it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7fdcc32-38ce-45e3-b0cb-e8f7735230b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4008\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of the dataset: \n",
    "rows, columns = df.shape\n",
    "\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b536e80-e281-4c20-b1d5-11bcc900be07",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "- Determine the data types of each column and evaluate whether they are appropriate for the nature of the variable. You should also provide suggestions for fixing any incorrect data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e258d7-df6f-4d49-bca9-ac6cb7871ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer                      object\n",
      "ST                            object\n",
      "GENDER                        object\n",
      "Education                     object\n",
      "Customer Lifetime Value       object\n",
      "Income                       float64\n",
      "Monthly Premium Auto         float64\n",
      "Number of Open Complaints     object\n",
      "Policy Type                   object\n",
      "Vehicle Class                 object\n",
      "Total Claim Amount           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data types of each column\n",
    "data_types = df.dtypes\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820d055-390f-4a57-ba44-784cd90a70ec",
   "metadata": {},
   "source": [
    "### Suggestions for fixing incorrect data types:\n",
    "- __Customer__: This variable can be a string.\n",
    "- __ST__: This variable can be a string.\n",
    "- __Gender__: This variable can be a string.\n",
    "- __Education__: This variable can be a string.\n",
    "- __Customer Lifetime Value__: By definition this is a monetary value, not a percentage.  The best data type for this column is *float* because it may involve decimal places (e.g., $2500.75).\n",
    "- __Number of Open Complaints__: This should be an *integer* data type and not a date data type. This is because it counts the number of complains, which is inherently a discrete, non-negative quantity.\n",
    "- __Policy Type__: This variable can be a string.\n",
    "- __Vehicle Class__: This variable can be a string.\n",
    "- I think it's also important to add the units as part of the label for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60db85a-576b-45c6-b5b4-ec546a10b697",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "- Identify the number of unique values for each column and determine which columns appear to be categorical. You should also describe the unique values of each categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33b27c7d-787d-460e-b4e6-5e97a2a47f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer                     1071\n",
      "ST                              8\n",
      "GENDER                          5\n",
      "Education                       6\n",
      "Customer Lifetime Value      1027\n",
      "Income                        774\n",
      "Monthly Premium Auto          132\n",
      "Number of Open Complaints       6\n",
      "Policy Type                     3\n",
      "Vehicle Class                   6\n",
      "Total Claim Amount            761\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of unique values for each column\n",
    "unique_values = df.nunique()\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79dc63c-5b5f-4fe3-ac46-a2bdf11e6d9d",
   "metadata": {},
   "source": [
    "### Categorial columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7e47f0e-4b75-4ec8-ad32-0c2a2aaa5677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for 'ST' are: ['Washington' 'Arizona' 'Nevada' 'California' 'Oregon' 'Cali' 'AZ' 'WA'\n",
      " nan]\n",
      "\n",
      "The unique values for 'GENDER' are: [nan 'F' 'M' 'Femal' 'Male' 'female']\n",
      "\n",
      "The unique values for 'Education' are: ['Master' 'Bachelor' 'High School or Below' 'College' 'Bachelors' 'Doctor'\n",
      " nan]\n",
      "\n",
      "The unique values for 'Number of Open Complaints' are: ['1/0/00' '1/2/00' '1/1/00' '1/3/00' '1/5/00' '1/4/00' nan]\n",
      "\n",
      "The unique values for 'Policy Type' are: ['Personal Auto' 'Corporate Auto' 'Special Auto' nan]\n",
      "\n",
      "The unique values for 'Vehicle Class' are: ['Four-Door Car' 'Two-Door Car' 'SUV' 'Luxury SUV' 'Sports Car'\n",
      " 'Luxury Car' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ST - State where customers live\n",
    "# Columns with a small number of unique values relative to the number of rows are likely categorical:\n",
    "\n",
    "columns = [\"ST\", \"GENDER\", \"Education\", \"Number of Open Complaints\", \"Policy Type\", \"Vehicle Class\"]\n",
    "\n",
    "for col in columns:\n",
    "    unique_values = df[col].unique()\n",
    "    print(f\"The unique values for '{col}' are: {unique_values}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb2217-d305-4811-b1ad-03ef0512eb3a",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "- Provide the range of values for numerical columns, and give your insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f317c77-1f59-4d9b-9a79-449ad98b3310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:\n",
      " ['Income', 'Monthly Premium Auto', 'Total Claim Amount']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only numerical columns\n",
    "\n",
    "numeric_columns = df.select_dtypes(include = [float,int]).columns.tolist()\n",
    "print(f\"Numerical Columns:\\n {numeric_columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560af87-1932-41b2-8231-2cbcb8293da7",
   "metadata": {},
   "source": [
    "__\"Customer Lifetime Value\"__ and __\"Number of Open Complaints\"__ are also numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6d56e49-3305-4794-ad90-e81f520bc41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:\n",
      " ['Income', 'Monthly Premium Auto', 'Total Claim Amount', 'Customer Lifetime Value', 'Number of Open Complaints']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numeric_columns.append('Customer Lifetime Value')\n",
    "numeric_columns.append('Number of Open Complaints')\n",
    "print(f\"Numerical Columns:\\n {numeric_columns}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc26cd52-cce8-4bda-ae87-a8ab80ab59f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Range of values for Numerical Columns:\n",
      "\n",
      "Column: Income\n",
      "Min: 0.0, Max: 99960.0\n",
      "\n",
      "Column: Monthly Premium Auto\n",
      "Min: 61.0, Max: 35354.0\n",
      "\n",
      "Column: Total Claim Amount\n",
      "Min: 0.382107, Max: 2893.239678\n"
     ]
    }
   ],
   "source": [
    "# range of values for numerical columns\n",
    "\n",
    "numeric_columns = df.select_dtypes(include = [float,int]).columns.tolist()\n",
    "print(\"\\nRange of values for Numerical Columns:\")\n",
    "for col in numeric_columns:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Min: {df[col].min()}, Max: {df[col].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7292c-ad04-404a-a025-9bc19059cf5f",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "- Compute summary statistics such as mean, median, mode, standard deviation, and quartiles to understand the central tendency and distribution of the data for numerical columns. You should also provide your conclusions based on these summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "42a9d1af-489f-4519-96f7-ac734ed1f854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Monthly Premium Auto</th>\n",
       "      <th>Total Claim Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39295.701214</td>\n",
       "      <td>193.234360</td>\n",
       "      <td>404.986909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30469.427060</td>\n",
       "      <td>1601.190369</td>\n",
       "      <td>293.027260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.382107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14072.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>202.157702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36234.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>354.729129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64631.000000</td>\n",
       "      <td>109.500000</td>\n",
       "      <td>532.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99960.000000</td>\n",
       "      <td>35354.000000</td>\n",
       "      <td>2893.239678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Income  Monthly Premium Auto  Total Claim Amount\n",
       "count   1071.000000           1071.000000         1071.000000\n",
       "mean   39295.701214            193.234360          404.986909\n",
       "std    30469.427060           1601.190369          293.027260\n",
       "min        0.000000             61.000000            0.382107\n",
       "25%    14072.000000             68.000000          202.157702\n",
       "50%    36234.000000             83.000000          354.729129\n",
       "75%    64631.000000            109.500000          532.800000\n",
       "max    99960.000000          35354.000000         2893.239678"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a148ad-4f59-42fb-b88d-a6754fe0df6c",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "- The average income is approximately 39,296€\n",
    "- The standard deviation is about 30,469€, indicating significant variability in income levels\n",
    "- The minimum income is 0, indicating that some customers have no income recorded.\n",
    "- 25% have an income below 14,072€\n",
    "- The median income is $36,234 € (half of the observations have an income below this value.)\n",
    "- 75% have an income below 64,631€\n",
    "- The maximum income is 99,960€\n",
    "\n",
    "Conclusions: \n",
    "- The income distribution is quite spread out, with a large standard deviation relative to the mean. The presence of a $0 income suggests that some individuals might be unemployed, underreporting income, or have zero recorded income for other reasons.\n",
    "- The distribution of the 'monthly premium auto' is highly skewed, likely due to some outliers with very high premiums. The median value (83€) is significantly lower than the mean (193€).\n",
    "- The distribution of total claim amounts appears fairly concentrated around the mean, with a few larger claims pushing the maximum up to nearly 2,900. The minimum claim amount being very low suggests that there are some very small claims in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42d0f7-c052-4890-aef0-5f4a14a42370",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "- Compute summary statistics for categorical columns and providing your conclusions based on these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d2e02bf-ffee-4847-a959-84a915b0297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for 'ST':\n",
      "            Count  Percentage\n",
      "ST                           \n",
      "Oregon        320   29.878618\n",
      "California    211   19.701214\n",
      "Arizona       186   17.366947\n",
      "Cali          120   11.204482\n",
      "Nevada         98    9.150327\n",
      "Washington     81    7.563025\n",
      "WA             30    2.801120\n",
      "AZ             25    2.334267\n",
      "\n",
      "Summary for 'GENDER':\n",
      "        Count  Percentage\n",
      "GENDER                   \n",
      "F         457   47.903564\n",
      "M         413   43.291405\n",
      "Male       39    4.088050\n",
      "female     28    2.935010\n",
      "Femal      17    1.781971\n",
      "\n",
      "Summary for 'Education':\n",
      "                      Count  Percentage\n",
      "Education                              \n",
      "Bachelor                324   30.252101\n",
      "College                 313   29.225023\n",
      "High School or Below    296   27.637722\n",
      "Master                   94    8.776844\n",
      "Doctor                   37    3.454715\n",
      "Bachelors                 7    0.653595\n",
      "\n",
      "Summary for 'Number of Open Complaints':\n",
      "                           Count  Percentage\n",
      "Number of Open Complaints                   \n",
      "1/0/00                       830   77.497666\n",
      "1/1/00                       138   12.885154\n",
      "1/2/00                        50    4.668534\n",
      "1/3/00                        34    3.174603\n",
      "1/4/00                        13    1.213819\n",
      "1/5/00                         6    0.560224\n",
      "\n",
      "Summary for 'Policy Type':\n",
      "                Count  Percentage\n",
      "Policy Type                      \n",
      "Personal Auto     780   72.829132\n",
      "Corporate Auto    234   21.848739\n",
      "Special Auto       57    5.322129\n",
      "\n",
      "Summary for 'Vehicle Class':\n",
      "               Count  Percentage\n",
      "Vehicle Class                   \n",
      "Four-Door Car    576   53.781513\n",
      "Two-Door Car     205   19.140990\n",
      "SUV              199   18.580766\n",
      "Sports Car        57    5.322129\n",
      "Luxury SUV        20    1.867414\n",
      "Luxury Car        14    1.307190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the Occurrences and Percentage of Each Category\n",
    "\n",
    "columns = [\"ST\", \"GENDER\", \"Education\", \"Number of Open Complaints\", \"Policy Type\", \"Vehicle Class\"]\n",
    "\n",
    "for col in columns:\n",
    "    count = df[col].value_counts()\n",
    "    percentage = df[col].value_counts(normalize=True) * 100\n",
    "    result = pd.DataFrame({'Count': count, 'Percentage': percentage})\n",
    "    print(f\"Summary for '{col}':\\n{result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e00cd-c3cb-47f6-9370-ccf21cba72c1",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- Oregon is the most common state with 29.88% of the customers, followed by California (19.70%) and Arizona (17.37%).\n",
    "- Females (F) make up 47.90% of the customers, while Males (M) account for 43.29%.\n",
    "- The data suggests that customers are fairly well-educated, with over 87% having education beyond high school.\n",
    "- Only a small percentage of customers have more than one complaint (about 12% with 1 complaint and less than 11% with more than 1), indicating relatively high customer satisfaction\n",
    "- The distribution suggests that the majority of customers own standard vehicles, with sports and luxury cars being much less common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1ae0259-434c-43bf-a3e1-f983666dc8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top value for the ST is Oregon:\n",
      "\n",
      "The top value for the GENDER is F:\n",
      "\n",
      "The top value for the Education is Bachelor:\n",
      "\n",
      "The top value for the Number of Open Complaints is 1/0/00:\n",
      "\n",
      "The top value for the Policy Type is Personal Auto:\n",
      "\n",
      "The top value for the Vehicle Class is Four-Door Car:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculation of the most frecuent value (top) for each category\n",
    "\n",
    "columns = [\"ST\", \"GENDER\", \"Education\", \"Number of Open Complaints\", \"Policy Type\", \"Vehicle Class\"]\n",
    "\n",
    "for col in columns:\n",
    "    categorical_mode = df[col].describe().top\n",
    "    print(f\"The top value for the {col} is {categorical_mode}:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776a403-c56a-452f-ac33-5fd4fdb06fc7",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbc484-da4d-4f9c-9343-e1d44311a87e",
   "metadata": {},
   "source": [
    "The marketing team wants to know the top 5 less common customer locations. Create a pandas Series object that contains the customer locations and their frequencies, and then retrieve the top 5 less common locations in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2dca5073-4520-4f42-9390-4b92733284ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ST\n",
       "AZ             25\n",
       "WA             30\n",
       "Washington     81\n",
       "Nevada         98\n",
       "Cali          120\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the occurrences of each state\n",
    "location_counts = df['ST'].value_counts()\n",
    "\n",
    "# Sort the location_counts in ascending order to get the least common locations first\n",
    "sorted_locations = location_counts.sort_values(ascending=True)\n",
    "\n",
    "# top 5 least common locations\n",
    "top_5_least_common_locations = sorted_locations.head(5)\n",
    "display(top_5_least_common_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce80f43-4afa-43c7-a78a-c917444da4e0",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The sales team wants to know the total number of policies sold for each type of policy. Create a pandas Series object that contains the policy types and their total number of policies sold, and then retrieve the policy type with the highest number of policies sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f13997-1555-4f98-aca6-970fda1d2c3f",
   "metadata": {},
   "source": [
    "*Hint:*\n",
    "- *Using value_counts() method simplifies this analysis.*\n",
    "- *Futhermore, there is a method that returns the index of the maximum value in a column or row.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcfad6c1-9af2-4b0b-9aa9-0dc5c17473c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Policy Type\n",
       "Personal Auto     780\n",
       "Corporate Auto    234\n",
       "Special Auto       57\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "policy_counts = df['Policy Type'].value_counts()\n",
    "display(policy_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdb2c2a1-09fb-4050-929d-9e5f967ddfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy type with the highest number of policies sold: Personal Auto\n"
     ]
    }
   ],
   "source": [
    "most_common_policy = policy_counts.idxmax()\n",
    "\n",
    "print(f\"Policy type with the highest number of policies sold: {most_common_policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b863fd3-bf91-4d5d-86eb-be29ed9f5b70",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The sales team wants to know if customers with Personal Auto have a lower income than those with Corporate Auto. How does the average income compare between the two policy types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1386d75-2810-4aa1-93e0-9485aa12d552",
   "metadata": {},
   "source": [
    "- Use *loc* to create two dataframes: one containing only Personal Auto policies and one containing only Corporate Auto policies.\n",
    "- Calculate the average income for each policy.\n",
    "- Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c0563cf-6f8b-463d-a321-651a972f82e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average income for Personal Auto policies: 38181\n",
      "Average income for Corporate Auto policies: 41390\n"
     ]
    }
   ],
   "source": [
    "# Create two data frames:\n",
    "personal_auto_df = df.loc[df['Policy Type'] == \"Personal Auto\"]\n",
    "corporate_auto_df = df.loc[df['Policy Type'] == \"Corporate Auto\"]\n",
    "\n",
    "# average income for each policy type:\n",
    "average_income_personal_auto = personal_auto_df['Income'].mean()\n",
    "average_income_corporate_auto = corporate_auto_df['Income'].mean()\n",
    "\n",
    "\n",
    "print(f\"Average income for Personal Auto policies: {round(average_income_personal_auto)}\")\n",
    "print(f\"Average income for Corporate Auto policies: {round(average_income_corporate_auto)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b16c27-f4a5-4727-a229-1f88671cf4e2",
   "metadata": {},
   "source": [
    "### Bonus: Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac584986-299b-475f-ac2e-928c16c3f512",
   "metadata": {},
   "source": [
    "Your goal is to identify customers with a high policy claim amount.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Review again the statistics for total claim amount to gain an understanding of the data.\n",
    "- To identify potential areas for improving customer retention and profitability, we want to focus on customers with a high policy claim amount. Consider customers with a high policy claim amount to be those in the top 25% of the total claim amount. Create a pandas DataFrame object that contains information about customers with a policy claim amount greater than the 75th percentile.\n",
    "- Use DataFrame methods to calculate summary statistics about the high policy claim amount data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3af5f1-6023-4b05-9c01-d05392daa650",
   "metadata": {},
   "source": [
    "*Note: When analyzing data, we often want to focus on certain groups of values to gain insights. Percentiles are a useful tool to help us define these groups. A percentile is a measure that tells us what percentage of values in a dataset are below a certain value. For example, the 75th percentile represents the value below which 75% of the data falls. Similarly, the 25th percentile represents the value below which 25% of the data falls. When we talk about the top 25%, we are referring to the values that fall above the 75th percentile, which represent the top quarter of the data. On the other hand, when we talk about the bottom 25%, we are referring to the values that fall below the 25th percentile, which represent the bottom quarter of the data. By focusing on these groups, we can identify patterns and trends that may be useful for making decisions and taking action.*\n",
    "\n",
    "*Hint: look for a method that gives you the percentile or quantile 0.75 and 0.25 for a Pandas Series.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d234634-50bd-41e0-88f7-d5ba684455d1",
   "metadata": {},
   "source": [
    "*Hint 2: check `Boolean selection according to the values of a single column` in https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731bca6-a760-4860-a27b-a33efa712ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
